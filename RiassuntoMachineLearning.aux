\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Lezione 1 - Knn}{7}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}K-nn}{9}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Formula per il K-nn}{11}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Lezione 3 - Probabilistic Inference}{12}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Refresh: }{12}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}MLE: Ottimizzare la funzione Likelihood}{13}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Ottimizzare}{16}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Problemi della MLE}{18}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Bayesian Inference}{19}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Bayes Formula}{21}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Problema}{23}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}MAP: Maximum A Posterior Estimation}{24}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Scegliere la prior distribution}{24}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Calcolare la MAP}{26}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Estimate the posterior distribution}{28}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Vantaggi del calcolo completo della posterior distribution}{31}{subsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Soluzioni viste fino ad ora}{31}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Visualizzare la posterior distribution}{32}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Previsione del prossimo lancio}{33}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Linear Regression}{37}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Loss Function}{38}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}NonLinear Dependency in data}{40}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Come scegliere il grado del polinomio}{44}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Regularization}{46}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Bias - Variance tradeoff}{48}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Probabilistic Linear Regression}{51}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Bayesian Network}{51}{subsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Probabilistic Formulation of Linear Regression}{53}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Calcolare la Likelihood}{54}{subsection.3.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Calcolare la posterior Distribution}{57}{subsection.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Scegliere la prior distribution}{58}{section*.88}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Massimizzare la posterior distribution: MAP}{59}{section*.90}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Fully Bayesian Approach}{60}{subsection.3.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}Sequential Bayesian Linear Regression}{62}{subsection.3.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Un esempio di Sequential Bayesian Linear Regression}{62}{section*.100}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.5}Fare previsioni su nuovi dati}{65}{subsection.3.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Linear Classification}{69}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.0.1}Come capire se le previsioni sono corrette?}{70}{subsection.4.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.0.2}Usare l'iperpiano come decision boundary}{71}{subsection.4.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Multiple Classes}{73}{section*.115}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.0.3}Least Squares per la classificazione}{74}{subsection.4.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.0.4}Perceptron Algorithm}{75}{subsection.4.0.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Classi non linearmente separabili}{78}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Altre limitazioni}{79}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Probabilistic Model}{80}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Generative Model}{82}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Scegliere la prior distribution}{83}{section*.134}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Class conditionals}{86}{section*.142}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Posterior distribution}{88}{section*.149}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}LDA - Linear Discriminant Analysis}{89}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Estensione a pi\IeC {\`u} classi}{91}{section*.159}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Softmax function}{92}{section*.163}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Naive Bayes}{93}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Probabilistic Discriminative Models for linear classification}{95}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Logistic Regression}{96}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Likelihood della logistic Regression}{98}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Logistic Regressione e Weights regularization}{99}{subsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Multiclass logistic regression}{100}{subsection.4.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Loss nel caso della Multiclass logistic regression}{100}{section*.182}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Conclusioni}{101}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Optimization}{102}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.1}Convexity}{104}{subsection.5.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Convex Set}{104}{section*.186}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Convex Function}{104}{section*.188}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.2}Propriet\IeC {\`a} delle convex function}{105}{subsection.5.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.3}First Order Convexity Condition}{105}{subsection.5.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.4}Vertex}{108}{subsection.5.0.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.5}Convex hull}{108}{subsection.5.0.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Maximization Problem}{109}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Non con vex Set}{111}{section*.203}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Come verificare che una funzione \IeC {\`e} convessa}{111}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Verificare che un set \IeC {\`e} convesso}{112}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Problemi semplici}{113}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Coordinate descent}{113}{subsection.5.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Gradient Descent}{114}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Convergenza}{115}{section*.211}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Line search}{116}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Note}{118}{section*.217}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Parallel implementation}{118}{section*.219}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Un algoritmo pi\IeC {\`u} veloce}{119}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Possibili soluzioni per la scelta del learning rate}{121}{section*.224}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Adam: Adaptive Moment Estimation}{122}{section*.227}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Discussione e altri metodi}{123}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Metodo di Newton}{124}{subsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Note}{125}{section*.235}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Stochastic Gradient Descent}{126}{subsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Funzionamento}{126}{section*.236}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Esempio con il Perceptron}{127}{subsection.5.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Risolviamo con SGD}{129}{section*.245}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Ottimizzazione per la logistic regression}{130}{subsection.5.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.5}Distributed Learning}{130}{subsection.5.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Full gradient descent}{131}{section*.250}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Gradient Descent}{132}{section*.253}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Constrained Optimization}{133}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.0.1}Problemi standard}{134}{subsection.6.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Linear Programming}{134}{section*.258}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Quadratic Programming}{135}{section*.261}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Usare il Gradient Descent per risolvere problemi di Constrained Optimization}{136}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Calcolare le proiezioni}{138}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Note}{139}{subsection.6.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Lagrangian e Duality}{139}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Single Inequality Constraint}{139}{subsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Multiple Inequality Constraints}{143}{subsection.6.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Lagrangian}{145}{section*.278}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Esempio dal video}{147}{section*.282}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Lagrange dual function}{148}{section*.285}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Duality}{149}{section*.287}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Slater's constraint qualification}{151}{section*.290}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Soluzione di un constrained optimization problem}{152}{section*.292}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{KKT Condition}{153}{section*.294}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}SVM}{155}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Classificazione binaria}{155}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Iperpiani}{156}{section*.297}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}SVM con Hard Margin}{158}{section.7.2}\protected@file@percent }
\newlabel{eq4}{{7.1}{159}{SVM con Hard Margin}{equation.7.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Trovare w e b}{160}{section*.301}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Calcolo del margine come problema di ottimizzazione}{161}{section*.302}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Risolvere il problema di ottimizzazione della SVM}{162}{section*.303}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Risolvere il problema duale}{164}{section*.310}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Trovare w e b dalla soluzione duale}{165}{section*.312}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Soft Margin Support Vector Machine}{167}{section.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Slack Variables}{168}{section*.314}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig1}{{\caption@xref {fig1}{ on input line 3650}}{169}{Slack Variables}{figure.caption.317}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces \relax }}{169}{figure.caption.317}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Hinge Loss}{175}{section*.326}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Kernel}{176}{section.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Kernel Matrix (Gram Matrix)}{179}{section*.338}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Valid Kernel}{180}{section*.341}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Kernel Preserving Operations}{180}{section*.342}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.1}Esempi di Kernel}{180}{subsection.7.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Classificare un nuovo punto con SVM e Kernel}{181}{section.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Nota importante}{182}{section*.347}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.6}SVM con classi multiple}{184}{section.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Deep Learning}{185}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Introduzione}{185}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}Perch\IeC {\`e} usiamo i Deep Feedforward Network?}{186}{subsection.8.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Il dataset dello XOR}{187}{section.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}Esempio}{188}{subsection.8.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}Spiegazione e confronto con Logistic Regression}{191}{subsection.8.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Trovare la basis function}{194}{section*.361}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Neural Network pi\IeC {\`u} complicate}{196}{section*.364}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Activation Function}{198}{section*.367}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.3}Universal Approximation Theorem}{200}{subsection.8.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.4}Usare pi\IeC {\`u} layer}{200}{subsection.8.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Parameter Learning}{202}{section.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Esempio 1: Binary classification}{203}{section*.371}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Example 2: Multi-class classification}{204}{section*.373}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Esempio 3: Regressione}{205}{section*.376}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Minimizzazione della cost function}{205}{section.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.1}Come calcoliamo il gradiente?}{206}{subsection.8.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Jacobian}{209}{section*.380}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.2}Computational Graph}{211}{subsection.8.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.3}Example of BackPropagation}{214}{subsection.8.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.4}Computational Graph}{217}{subsection.8.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Ancora sulla BackPropagation}{220}{section*.396}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.5}Note}{221}{section.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Deep Learning 2}{223}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.1}Altri utilizzi per le NN}{223}{subsection.9.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Layer e CNN}{224}{section.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.1}CNN}{225}{subsection.9.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Motivation}{227}{section*.403}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Come \IeC {\`e} definita la CNN}{230}{section*.406}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Un esempio}{231}{section*.409}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Come ci comportiamo sui bordi dell'immagine?}{233}{section*.411}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Strides}{234}{section*.412}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pooling}{234}{section*.413}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Summary}{236}{section*.415}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}RNN: Recurrent Neural Networks}{236}{section.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Unfolding computational Graph}{237}{subsection.9.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}RNN e training}{241}{subsection.9.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Training}{243}{section*.426}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Weight Sharing}{244}{section*.427}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Training Deep Neural Networks}{244}{section.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Xavier Glorot Initialization}{245}{section*.428}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Regularization}{247}{section.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Ottimizzazione degli iperparametri}{249}{section*.434}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.5}Modern Architecture and Tricks}{250}{section.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.1}Batch Normalization}{250}{subsection.9.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.2}Attention}{252}{subsection.9.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.3}Tips and Tricks}{254}{subsection.9.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Introduction to PyTorch}{255}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Manually Setup the Affine Layer}{255}{section.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Declare the layer using PyTorch}{256}{section.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.1}nn.Linear}{257}{subsection.10.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.2}Torch.optim}{257}{subsection.10.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.3}DataLoader}{258}{subsection.10.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Validation}{258}{section.10.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Implement a CNN using PyTorch}{258}{section.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.4.1}nn.Sequential}{259}{subsection.10.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Math Refresh}{261}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Loss function}{261}{section.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.2}0-1 Loss}{261}{section.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Lagrange Multipliers}{263}{section.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Lagrange multiplier con vincoli $\geq $}{264}{section*.442}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Probability Distribution}{265}{section.11.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4.1}Bernoulli Distribution}{266}{subsection.11.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4.2}Normal Distribution}{266}{subsection.11.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4.3}Beta Distribution}{267}{subsection.11.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4.4}Categorical Distribution}{268}{subsection.11.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Propriet\IeC {\`a} dei logaritmi}{268}{section.11.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.6}Derivate}{268}{section.11.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.7}Integrali}{269}{section.11.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.8}Derivate di matrici e Vettori}{270}{section.11.8}\protected@file@percent }
