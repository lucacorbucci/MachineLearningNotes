\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Lezione 1 - Knn}{8}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}K-nn}{10}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Formula per il K-nn}{12}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Cost sensitive Learning}{13}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Weighted K-nn}{13}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{K-nn per regressione}{14}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Come scegliere la K migliore?}{15}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Misure di performance}{17}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Distance Measure}{22}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Interpretazione probabilistica di K-nn}{25}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Problemi noti}{27}{subsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Scaling Issue}{27}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Curse of Dimensionality}{28}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Considerazioni su K-nn}{29}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Decision Tree}{30}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.1}Introduzione}{30}{subsection.2.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.2}Inferenza con i decision tree}{34}{subsection.2.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.3}Creare il decision Tree ottimo}{35}{subsection.2.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Algoritmo Greedy}{36}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Lezione 3 - Probabilistic Inference}{37}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Refresh: }{37}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}MLE: Ottimizzare la funzione Likelihood}{38}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Ottimizzare}{41}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Problemi della MLE}{43}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Bayesian Inference}{44}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Bayes Formula}{46}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Problema}{48}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}MAP: Maximum A Posterior Estimation}{49}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Scegliere la prior distribution}{49}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Calcolare la MAP}{51}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Estimate the posterior distribution}{53}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Vantaggi del calcolo completo della posterior distribution}{56}{subsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Soluzioni viste fino ad ora}{56}{section*.73}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Visualizzare la posterior distribution}{57}{section*.75}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Previsione del prossimo lancio}{58}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Linear Regression}{62}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Loss Function}{63}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}NonLinear Dependency in data}{65}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Come scegliere il grado del polinomio}{69}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Regularization}{71}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Bias - Variance tradeoff}{73}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Probabilistic Linear Regression}{76}{section.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Bayesian Network}{76}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Probabilistic Formulation of Linear Regression}{78}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Calcolare la Likelihood}{79}{subsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Calcolare la posterior Distribution}{82}{subsection.4.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Scegliere la prior distribution}{83}{section*.128}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Massimizzare la posterior distribution: MAP}{84}{section*.130}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Fully Bayesian Approach}{85}{subsection.4.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Sequential Bayesian Linear Regression}{87}{subsection.4.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Un esempio di Sequential Bayesian Linear Regression}{87}{section*.140}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.5}Fare previsioni su nuovi dati}{90}{subsection.4.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Linear Classification}{94}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.1}Come capire se le previsioni sono corrette?}{95}{subsection.5.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.2}Usare l'iperpiano come decision boundary}{96}{subsection.5.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Multiple Classes}{98}{section*.155}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.3}Least Squares per la classificazione}{99}{subsection.5.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.4}Perceptron Algorithm}{100}{subsection.5.0.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Classi non linearmente separabili}{103}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Altre limitazioni}{104}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Probabilistic Model}{105}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Generative Model}{107}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Scegliere la prior distribution}{108}{section*.174}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Class conditionals}{111}{section*.182}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Posterior distribution}{113}{section*.189}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}LDA - Linear Discriminant Analysis}{114}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Estensione a pi\IeC {\`u} classi}{116}{section*.199}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Softmax function}{117}{section*.203}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Naive Bayes}{118}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Probabilistic Discriminative Models for linear classification}{120}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Logistic Regression}{121}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Likelihood della logistic Regression}{123}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Logistic Regressione e Weights regularization}{124}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Multiclass logistic regression}{125}{subsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Loss nel caso della Multiclass logistic regression}{125}{section*.222}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Conclusioni}{126}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Optimization}{127}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.0.1}Convexity}{129}{subsection.6.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Convex Set}{129}{section*.226}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Convex Function}{129}{section*.228}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.0.2}Propriet\IeC {\`a} delle convex function}{130}{subsection.6.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.0.3}First Order Convexity Condition}{130}{subsection.6.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.0.4}Vertex}{133}{subsection.6.0.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.0.5}Convex hull}{133}{subsection.6.0.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Maximization Problem}{134}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Non con vex Set}{136}{section*.243}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Come verificare che una funzione \IeC {\`e} convessa}{136}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Verificare che un set \IeC {\`e} convesso}{137}{subsection.6.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}Problemi semplici}{138}{subsection.6.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.4}Coordinate descent}{138}{subsection.6.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Gradient Descent}{139}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Convergenza}{140}{section*.251}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Line search}{141}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Note}{143}{section*.257}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Parallel implementation}{143}{section*.259}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Un algoritmo pi\IeC {\`u} veloce}{144}{subsection.6.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Possibili soluzioni per la scelta del learning rate}{146}{section*.264}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Adam: Adaptive Moment Estimation}{147}{section*.267}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Discussione e altri metodi}{148}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Metodo di Newton}{149}{subsection.6.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Note}{150}{section*.275}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Stochastic Gradient Descent}{151}{subsection.6.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Funzionamento}{151}{section*.276}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.3}Esempio con il Perceptron}{152}{subsection.6.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Risolviamo con SGD}{154}{section*.285}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.4}Ottimizzazione per la logistic regression}{155}{subsection.6.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.5}Distributed Learning}{155}{subsection.6.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Full gradient descent}{156}{section*.290}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Gradient Descent}{157}{section*.293}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Constrained Optimization}{158}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.0.1}Problemi standard}{159}{subsection.7.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Linear Programming}{159}{section*.298}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Quadratic Programming}{160}{section*.301}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Usare il Gradient Descent per risolvere problemi di Constrained Optimization}{161}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Calcolare le proiezioni}{163}{subsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Note}{164}{subsection.7.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Lagrangian e Duality}{164}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Single Inequality Constraint}{164}{subsection.7.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}Multiple Inequality Constraints}{168}{subsection.7.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Lagrangian}{170}{section*.318}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Esempio dal video}{172}{section*.322}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Lagrange dual function}{173}{section*.325}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Duality}{174}{section*.327}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Slater's constraint qualification}{176}{section*.330}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Soluzione di un constrained optimization problem}{177}{section*.332}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{KKT Condition}{178}{section*.334}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {8}SVM}{180}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Classificazione binaria}{180}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Iperpiani}{181}{section*.337}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}SVM con Hard Margin}{183}{section.8.2}\protected@file@percent }
\newlabel{eq4}{{8.1}{184}{SVM con Hard Margin}{equation.8.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Trovare w e b}{185}{section*.341}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Calcolo del margine come problema di ottimizzazione}{186}{section*.342}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Risolvere il problema di ottimizzazione della SVM}{187}{section*.343}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Risolvere il problema duale}{189}{section*.350}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Trovare w e b dalla soluzione duale}{190}{section*.352}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Soft Margin Support Vector Machine}{192}{section.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Slack Variables}{193}{section*.354}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig1}{{\caption@xref {fig1}{ on input line 4091}}{194}{Slack Variables}{figure.caption.357}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces \relax }}{194}{figure.caption.357}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Hinge Loss}{200}{section*.366}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Kernel}{201}{section.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Kernel Matrix (Gram Matrix)}{204}{section*.378}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Valid Kernel}{205}{section*.381}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Kernel Preserving Operations}{205}{section*.382}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.1}Esempi di Kernel}{205}{subsection.8.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.5}Classificare un nuovo punto con SVM e Kernel}{206}{section.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Nota importante}{207}{section*.387}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.6}SVM con classi multiple}{209}{section.8.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Deep Learning}{210}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Introduzione}{210}{section.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.1}Perch\IeC {\`e} usiamo i Deep Feedforward Network?}{211}{subsection.9.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Il dataset dello XOR}{212}{section.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Esempio}{213}{subsection.9.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}Spiegazione e confronto con Logistic Regression}{216}{subsection.9.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Trovare la basis function}{219}{section*.401}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Neural Network pi\IeC {\`u} complicate}{221}{section*.404}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Activation Function}{223}{section*.407}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.3}Universal Approximation Theorem}{225}{subsection.9.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.4}Usare pi\IeC {\`u} layer}{225}{subsection.9.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Parameter Learning}{227}{section.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Esempio 1: Binary classification}{228}{section*.411}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Example 2: Multi-class classification}{229}{section*.413}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Esempio 3: Regressione}{230}{section*.416}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Minimizzazione della cost function}{230}{section.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.1}Come calcoliamo il gradiente?}{231}{subsection.9.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Jacobian}{234}{section*.420}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.2}Computational Graph}{236}{subsection.9.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.3}Example of BackPropagation}{239}{subsection.9.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.4}Computational Graph}{242}{subsection.9.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Ancora sulla BackPropagation}{245}{section*.436}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.5}Note}{246}{section.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Deep Learning 2}{248}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.0.1}Altri utilizzi per le NN}{248}{subsection.10.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Layer e CNN}{249}{section.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.1}CNN}{250}{subsection.10.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Motivation}{252}{section*.443}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Come \IeC {\`e} definita la CNN}{255}{section*.446}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Un esempio}{256}{section*.449}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Come ci comportiamo sui bordi dell'immagine?}{258}{section*.451}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Strides}{259}{section*.452}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pooling}{259}{section*.453}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Summary}{261}{section*.455}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.2}RNN: Recurrent Neural Networks}{261}{section.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.1}Unfolding computational Graph}{262}{subsection.10.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.2}RNN e training}{266}{subsection.10.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Training}{268}{section*.466}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Weight Sharing}{269}{section*.467}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Training Deep Neural Networks}{269}{section.10.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Xavier Glorot Initialization}{270}{section*.468}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Regularization}{272}{section.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Ottimizzazione degli iperparametri}{274}{section*.474}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.5}Modern Architecture and Tricks}{275}{section.10.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.1}Batch Normalization}{275}{subsection.10.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.2}Attention}{277}{subsection.10.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.3}Tips and Tricks}{279}{subsection.10.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Dimension Reduction}{280}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.0.1}Unsupervised Learning}{280}{subsection.11.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.0.2}Dimensionality Reduction}{281}{subsection.11.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature selection}{283}{section*.480}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Linear Transformation}{284}{section*.484}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Principal Component Analysis}{288}{section.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Come troviamo la trasformazione}{289}{section*.488}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Dimensionality Reduction with PCA}{293}{section*.495}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Complessit\IeC {\`a}}{295}{section*.497}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Come si calcolano gli autovettori}{295}{section*.498}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Introduction to PyTorch}{298}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Manually Setup the Affine Layer}{298}{section.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.2}Declare the layer using PyTorch}{299}{section.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.1}nn.Linear}{300}{subsection.12.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.2}Torch.optim}{300}{subsection.12.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.3}DataLoader}{301}{subsection.12.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Validation}{301}{section.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.4}Implement a CNN using PyTorch}{301}{section.12.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.4.1}nn.Sequential}{302}{subsection.12.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Math Refresh}{304}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Loss function}{304}{section.13.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.2}0-1 Loss}{304}{section.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Lagrange Multipliers}{306}{section.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Lagrange multiplier con vincoli $\geq $}{307}{section*.503}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.4}Probability Distribution}{308}{section.13.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.1}Bernoulli Distribution}{309}{subsection.13.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.2}Normal Distribution}{309}{subsection.13.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.3}Beta Distribution}{310}{subsection.13.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.4}Categorical Distribution}{311}{subsection.13.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.5}Propriet\IeC {\`a} dei logaritmi}{311}{section.13.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.6}Derivate}{311}{section.13.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.7}Integrali}{312}{section.13.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.8}Derivate di matrici e Vettori}{313}{section.13.8}\protected@file@percent }
